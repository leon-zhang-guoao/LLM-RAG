import gradio as gr
import os
import re
import uuid
import time
from langchain.embeddings.base import Embeddings
from langchain.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import PyPDFLoader
import fitz
from PIL import Image
import chromadb
from smolagents import Tool, CodeAgent, LiteLLMModel
import google.generativeai as genai
import tiktoken
from dotenv import load_dotenv

os.environ["GEMINI_API_KEY"] = "key"
os.environ["DEEPSEEK_API_KEY"] = "key"

# é…ç½® API å¯†é’¥
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")  # ä½¿ç”¨ GOOGLE_API_KEY
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# é…ç½® Gemini API
genai.configure(api_key=GOOGLE_API_KEY)  # ä½¿ç”¨ GOOGLE_API_KEY

# Tokenizerï¼ˆç”¨äºæ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼‰
encoding = tiktoken.encoding_for_model("text-embedding-ada-002")

# è‡ªå®šä¹‰ Gemini Embeddings ç±»
class GeminiEmbeddings(Embeddings):
    def __init__(self, api_key: str):
        self.api_key = api_key
        genai.configure(api_key=self.api_key)

    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        """å°†æ–‡æœ¬åˆ—è¡¨è½¬æ¢ä¸ºå‘é‡åˆ—è¡¨ã€‚"""
        try:
            embeddings = []
            for text in texts:
                result = genai.embed_content(model="models/text-embedding-004", content=text)
                embeddings.append(result['embedding'])
                time.sleep(60 / 1500)  # é€Ÿç‡é™åˆ¶
            return embeddings
        except Exception as e:
            print(f"Gemini Embeddings API è¯·æ±‚å¤±è´¥: {e}")
            return []

    def embed_query(self, text: str) -> list[float]:
        """å°†å•ä¸ªæ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ã€‚"""
        try:
            result = genai.embed_content(model="models/text-embedding-004", content=text)
            return result['embedding']
        except Exception as e:
            print(f"Gemini Embeddings API è¯·æ±‚å¤±è´¥: {e}")
            return []

# PDF é¡µé¢æ¸²æŸ“å‡½æ•°
def render_pdf_page(file, page_number=0):
    doc = fitz.open(file.name)
    page = doc[page_number]
    pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))
    image = Image.frombytes('RGB', [pix.width, pix.height], pix.samples)
    return image

def render_file(file):
    return render_pdf_page(file, app.N)

def render_first(file):
    return render_pdf_page(file, 0), []

# Gradio å›è°ƒå‡½æ•°
def set_apikey(api_key: str):
    app.OPENAI_API_KEY = api_key
    return gr.Textbox.update(value='DS API key is Set', interactive=False)

def enable_api_box():
    return gr.Textbox.update(value=None, placeholder='Upload your DS API key', interactive=True)

def add_text(history, text: str):
    if not text:
        raise gr.Error('Enter text')
    # å°†å­—å…¸åˆ—è¡¨è½¬æ¢ä¸ºåˆ—è¡¨çš„åˆ—è¡¨
    history = history + [[text, ""]]  # ç”¨æˆ·æ¶ˆæ¯å’Œç©ºçš„åŠ©æ‰‹æ¶ˆæ¯
    return history

def get_response(history, query, file):
    if not file:
        raise gr.Error(message='Upload a PDF')
    try:
        chain = app(file.name)
        result = chain({"question": query, 'chat_history': app.chat_history}, return_only_outputs=True)
        app.chat_history += [(query, result["answer"])]
        app.N = list(result['source_documents'][0])[1][1]['page']
        # å°†åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ° history ä¸­
        history[-1][1] = result["answer"]  # æ›´æ–°æœ€åä¸€ä¸ªæ¶ˆæ¯çš„åŠ©æ‰‹éƒ¨åˆ†
        yield history, ''
    except Exception as e:
        print(f"Error in get_response: {e}")
        history[-1][1] = f"An error occurred: {str(e)}"  # æ›´æ–°é”™è¯¯æ¶ˆæ¯
        yield history, ''

# è‡ªå®šä¹‰å·¥å…·ç±»
class my_app(Tool):
    def __init__(self, OPENAI_API_KEY: str = None) -> None:
        super().__init__()
        self.OPENAI_API_KEY: str = OPENAI_API_KEY
        self.chain = None
        self.chat_history: list = []
        self.N: int = 0
        self.count: int = 0
        self.description = "This is a custom tool for handling PDF files and conversational retrieval."
        self.name = "PDF Conversational Tool"
        self.inputs = {
            "file": {"description": "The PDF file to process", "type": "string"}
        }
        self.output_type = "any"

    def forward(self, file: str):
        if self.count == 0:
            self.chain = self.build_chain(file)
            self.count += 1
        return self.chain

    def process_file(self, file: str):
        loader = PyPDFLoader(file)
        documents = loader.load()
        file_name = os.path.basename(file)
        return documents, file_name

    def build_chain(self, file: str):
        documents, file_name = self.process_file(file)

        # ä½¿ç”¨è‡ªå®šä¹‰çš„ GeminiEmbeddings
        embeddings = GeminiEmbeddings(api_key=GOOGLE_API_KEY)

        # å°†æ–‡æ¡£å’Œ Embeddings å­˜å‚¨åˆ° Chroma
        pdfsearch = Chroma.from_documents(
            documents,
            embeddings,
            collection_name=file_name,
        )

        # æ„å»ºé—®ç­”é“¾
        chain = ConversationalRetrievalChain.from_llm(
            ChatOpenAI(model='deepseek-chat', openai_api_key=self.OPENAI_API_KEY, openai_api_base='https://api.deepseek.com', max_tokens=2048),
            retriever=pdfsearch.as_retriever(search_kwargs={"k": 1}),
            return_source_documents=True,
        )
        return chain

# åˆå§‹åŒ–åº”ç”¨
app = my_app(OPENAI_API_KEY=DEEPSEEK_API_KEY)
deepseek_model = LiteLLMModel(model_id="deepseek/deepseek-chat", api_key=DEEPSEEK_API_KEY)

agent = CodeAgent(
    tools=[app],
    additional_authorized_imports=['datetime', 'queue', 'statistics', 're', 'math', 'random', 'unicodedata', 'collections', 'time', 'itertools', 'stat', 'matplotlib', 'pandas', 'langchain'],
    model=deepseek_model
)

# Gradio ç•Œé¢
with gr.Blocks() as demo:
    with gr.Column():
        with gr.Row():
            with gr.Column(scale=8):
                api_key = gr.Textbox(placeholder='Enter DS API key', show_label=False, interactive=True, label="API Key")
            with gr.Column(scale=2):
                change_api_key = gr.Button('Change Key', variant="primary")
        with gr.Row():
            chatbot = gr.Chatbot(value=[], elem_id='chatbot', label="Chatbot")
            show_img = gr.Image(label='Upload PDF', height=680)
    with gr.Row():
        with gr.Column(scale=6):
            txt = gr.Textbox(show_label=False, placeholder="Enter text and press enter", label="Input")
        with gr.Column(scale=2):
            submit_btn = gr.Button('Submit', variant="primary")
        with gr.Column(scale=2):
            btn = gr.UploadButton("ğŸ“ Upload PDF", file_types=[".pdf"], variant="primary")

    api_key.submit(
        fn=set_apikey,
        inputs=[api_key],
        outputs=[api_key]
    )
    change_api_key.click(
        fn=enable_api_box,
        outputs=[api_key]
    )
    btn.upload(
        fn=render_first,
        inputs=[btn],
        outputs=[show_img, chatbot]
    )
    submit_btn.click(
        fn=add_text,
        inputs=[chatbot, txt],
        outputs=[chatbot],
        queue=False
    ).success(
        fn=get_response,
        inputs=[chatbot, txt, btn],
        outputs=[chatbot, txt]
    ).success(
        fn=render_file,
        inputs=[btn],
        outputs=[show_img]
    )

# å¯åŠ¨åº”ç”¨
demo.queue()
demo.launch(server_name="host")